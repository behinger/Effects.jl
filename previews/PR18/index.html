<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Effects.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://beacon-biosignals.github.io/Effects.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>Effects.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#The-Effect-of-Contrast-Coding"><span>The Effect of Contrast Coding</span></a></li><li><a class="tocitem" href="#Interaction-Terms-in-Effects"><span>Interaction Terms in Effects</span></a></li></ul></li><li><a class="tocitem" href="api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/beacon-biosignals/Effects.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Effects.jl"><a class="docs-heading-anchor" href="#Effects.jl">Effects.jl</a><a id="Effects.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Effects.jl" title="Permalink"></a></h1><p>Regression models are useful but they can be tricky to interpret. Variable centering and contrast coding can obscure the meaning of main effects. Interaction terms, especially higher order ones, only increase the difficulty of interpretation. Here, we introduce Effects.jl which translates the fitted model, including estimated uncertainty, back into data space. Using Effects.jl, it is possible to generate effects plots that enable rapid visualization and interpretation of regression models.</p><p>The examples below demonstrate the use of Effects.jl with GLM.jl, but they will work with any modeling package that is based on the <a href="https://juliastats.org/StatsModels.jl/stable/formula/">StatsModels.jl formula</a>. The second example is borrowed in no small part from <a href="https://beacon-biosignals.github.io/StandardizedPredictors.jl/dev/">StandardizedPredictors.jl</a>.</p><h2 id="The-Effect-of-Contrast-Coding"><a class="docs-heading-anchor" href="#The-Effect-of-Contrast-Coding">The Effect of Contrast Coding</a><a id="The-Effect-of-Contrast-Coding-1"></a><a class="docs-heading-anchor-permalink" href="#The-Effect-of-Contrast-Coding" title="Permalink"></a></h2><p>Let&#39;s consider a synthetic dataset of weights (in grams) for chicks feed different types of feed, with a single predictor <code>feed</code> (categorical, with three levels <code>A</code>, <code>B</code>, <code>C</code>). The simulated weights are based loosely on the R dataset <code>chickwts</code>.</p><pre><code class="language-julia">using AlgebraOfGraphics, CairoMakie, DataFrames, Effects, GLM, StatsModels, Random
rng = MersenneTwister(42)
reps = 10
sd = 50
wtdat = DataFrame(feed = repeat([&quot;A&quot;, &quot;B&quot;, &quot;C&quot;], inner=reps),
                  weight=[180 .+ sd*randn(rng, reps);
                          220 .+ sd*randn(rng, reps);
                          300 .+ sd*randn(rng, reps)])</code></pre><table class="data-frame"><thead><tr><th></th><th>feed</th><th>weight</th></tr><tr><th></th><th>String</th><th>Float64</th></tr></thead><tbody><p>30 rows × 2 columns</p><tr><th>1</th><td>A</td><td>152.199</td></tr><tr><th>2</th><td>A</td><td>157.781</td></tr><tr><th>3</th><td>A</td><td>181.358</td></tr><tr><th>4</th><td>A</td><td>165.026</td></tr><tr><th>5</th><td>A</td><td>268.893</td></tr><tr><th>6</th><td>A</td><td>122.755</td></tr><tr><th>7</th><td>A</td><td>156.57</td></tr><tr><th>8</th><td>A</td><td>187.807</td></tr><tr><th>9</th><td>A</td><td>47.9004</td></tr><tr><th>10</th><td>A</td><td>230.165</td></tr><tr><th>11</th><td>B</td><td>274.119</td></tr><tr><th>12</th><td>B</td><td>229.351</td></tr><tr><th>13</th><td>B</td><td>245.907</td></tr><tr><th>14</th><td>B</td><td>294.569</td></tr><tr><th>15</th><td>B</td><td>238.378</td></tr><tr><th>16</th><td>B</td><td>175.69</td></tr><tr><th>17</th><td>B</td><td>254.228</td></tr><tr><th>18</th><td>B</td><td>140.471</td></tr><tr><th>19</th><td>B</td><td>240.533</td></tr><tr><th>20</th><td>B</td><td>177.183</td></tr><tr><th>21</th><td>C</td><td>247.451</td></tr><tr><th>22</th><td>C</td><td>325.104</td></tr><tr><th>23</th><td>C</td><td>289.188</td></tr><tr><th>24</th><td>C</td><td>264.679</td></tr><tr><th>25</th><td>C</td><td>83.1266</td></tr><tr><th>26</th><td>C</td><td>328.491</td></tr><tr><th>27</th><td>C</td><td>228.897</td></tr><tr><th>28</th><td>C</td><td>281.38</td></tr><tr><th>29</th><td>C</td><td>318.451</td></tr><tr><th>30</th><td>C</td><td>299.619</td></tr></tbody></table><p>If we fit a linear model to this data using default treatment/dummy coding, then every term is significant:</p><pre><code class="language-julia">mod_treat = lm(@formula(weight ~ 1 + feed), wtdat)</code></pre><pre class="documenter-example-output">StatsModels.TableRegressionModel{GLM.LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}

weight ~ 1 + feed

Coefficients:
───────────────────────────────────────────────────────────────────────
                Coef.  Std. Error     t  Pr(&gt;|t|)  Lower 95%  Upper 95%
───────────────────────────────────────────────────────────────────────
(Intercept)  167.045      19.2055  8.70    &lt;1e-08  127.639      206.452
feed: B       59.9975     27.1607  2.21    0.0358    4.26843    115.727
feed: C       99.5932     27.1607  3.67    0.0011   43.8641     155.322
───────────────────────────────────────────────────────────────────────</pre><p>If on the other hand, we use effects (sum-to-zero) coding, then the term for feed <code>B</code> is no longer significant:</p><pre><code class="language-julia">mod_eff = lm(@formula(weight ~ 1 + feed), wtdat; contrasts=Dict(:feed =&gt; EffectsCoding()))</code></pre><pre class="documenter-example-output">StatsModels.TableRegressionModel{GLM.LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}

weight ~ 1 + feed

Coefficients:
─────────────────────────────────────────────────────────────────────────
                 Coef.  Std. Error      t  Pr(&gt;|t|)  Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────
(Intercept)  220.242       11.0883  19.86    &lt;1e-16   197.491    242.994
feed: B        6.80062     15.6812   0.43    0.6680   -25.3746    38.9758
feed: C       46.3963      15.6812   2.96    0.0064    14.2211    78.5715
─────────────────────────────────────────────────────────────────────────</pre><p>This is in some sense unsurprising: the different coding schemes correspond to different hypotheses. In treatment coding, the hypothesis for the term <code>feed: B</code> is whether feed <code>B</code> differs from the reference level, feed <code>A</code>. In effects coding, the hypothesis is whether feed <code>B</code> differs from the mean across all levels. In more complicated models, the hypotheses being tested – especially for interaction terms – can become more complex and difficult to &quot;read off&quot; from the model summary.</p><p>In spite of these differences, these models make the same predictions about the data:</p><pre><code class="language-julia">response(mod_treat) ≈ response(mod_eff)</code></pre><pre class="documenter-example-output">true</pre><p>At a deep level, these models are the actually same model, but with different parameterizations. In order to get a better view about what a model is saying about the data, abstracted away from the parameterization, we can see what the model looks like in data space. For that, we can use <code>Efffects.jl</code> to generate the <em>effects</em> that the model is capturing. We do this by specifying a (subset of the) design and creating a reference grid, then computing the model&#39;s prediction and associated error at those values.</p><p>The <code>effects</code> function will compute the reference grid for a fully-crossed design specified by a dictionary of values. As we only have one predictor in this dataset, the design is fully crossed.</p><pre><code class="language-julia">design = Dict(:feed =&gt; unique(wtdat.feed))
eff_feed = effects(design, @formula(weight ~ 1 + feed), mod_eff;
                   contrasts=Dict(:feed =&gt; EffectsCoding()))
eff_feed</code></pre><table class="data-frame"><thead><tr><th></th><th>feed</th><th>weight</th><th>err</th><th>lower</th><th>upper</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3 rows × 5 columns</p><tr><th>1</th><td>A</td><td>167.045</td><td>19.2055</td><td>147.84</td><td>186.251</td></tr><tr><th>2</th><td>B</td><td>227.043</td><td>19.2055</td><td>207.837</td><td>246.248</td></tr><tr><th>3</th><td>C</td><td>266.639</td><td>19.2055</td><td>247.433</td><td>285.844</td></tr></tbody></table><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>You must specify the contrasts for the new formula such that they exactly match the contrasts used in fitting the original model. In the future, automatic extraction of the contrasts from the fitted model will be supported.</p></div></div><p>The effects table consists of four columns: the levels of the <code>feed</code> predictor specified in the design (<code>feed</code>), the prediction of the model at those levels (<code>weight</code>), the standard error of those predictions <code>err</code>, and the lower and upper edges of confidence interval of those predictions (<code>lower</code>, <code>upper</code>; computed using a normal approximation based on the standard error).</p><pre><code class="language-julia">plt = data(eff_feed) * mapping(:feed, :weight) * (visual(Scatter) + mapping(:lower, :upper) * visual(Errorbars))
draw(plt)</code></pre><img src="data:image/png;base64,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" /><h2 id="Interaction-Terms-in-Effects"><a class="docs-heading-anchor" href="#Interaction-Terms-in-Effects">Interaction Terms in Effects</a><a id="Interaction-Terms-in-Effects-1"></a><a class="docs-heading-anchor-permalink" href="#Interaction-Terms-in-Effects" title="Permalink"></a></h2><p>Let&#39;s consider a (slightly) synthetic dataset of weights for adolescents of different ages, with predictors <code>age</code> (continuous, from 13 to 20) and <code>sex</code>, and <code>weight</code> in pounds.  The weights are based loosely on the medians from the <a href="https://www.cdc.gov/growthcharts/html_charts/wtage.htm">CDC growth charts</a>, which show that the median male and female both start off around 100 pounds at age 13, but by age 20 the median male weighs around 155 pounds while the median female weighs around 125 pounds.</p><pre><code class="language-julia">using AlgebraOfGraphics, CairoMakie, DataFrames, Effects, GLM, StatsModels, Random
rng = MersenneTwister(42)
growthdata = DataFrame(age=[13:20; 13:20],
                       sex=repeat([&quot;male&quot;, &quot;female&quot;], inner=8),
                       weight=[range(100, 155; length=8); range(100, 125; length=8)] .+ randn(rng, 16))</code></pre><table class="data-frame"><thead><tr><th></th><th>age</th><th>sex</th><th>weight</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th></tr></thead><tbody><p>16 rows × 3 columns</p><tr><th>1</th><td>13</td><td>male</td><td>99.444</td></tr><tr><th>2</th><td>14</td><td>male</td><td>107.413</td></tr><tr><th>3</th><td>15</td><td>male</td><td>115.741</td></tr><tr><th>4</th><td>16</td><td>male</td><td>123.272</td></tr><tr><th>5</th><td>17</td><td>male</td><td>133.206</td></tr><tr><th>6</th><td>18</td><td>male</td><td>138.141</td></tr><tr><th>7</th><td>19</td><td>male</td><td>146.674</td></tr><tr><th>8</th><td>20</td><td>male</td><td>155.156</td></tr><tr><th>9</th><td>13</td><td>female</td><td>97.358</td></tr><tr><th>10</th><td>14</td><td>female</td><td>104.575</td></tr><tr><th>11</th><td>15</td><td>female</td><td>108.225</td></tr><tr><th>12</th><td>16</td><td>female</td><td>110.901</td></tr><tr><th>13</th><td>17</td><td>female</td><td>114.804</td></tr><tr><th>14</th><td>18</td><td>female</td><td>119.349</td></tr><tr><th>15</th><td>19</td><td>female</td><td>121.796</td></tr><tr><th>16</th><td>20</td><td>female</td><td>124.114</td></tr></tbody></table><p>In this dataset, there&#39;s obviously a main effect of sex: males are heavier than females for every age except 13 years.  But if we run a basic linear regression, we see something rather different:</p><pre><code class="language-julia">mod_uncentered = lm(@formula(weight ~ 1 + sex * age), growthdata)</code></pre><pre class="documenter-example-output">StatsModels.TableRegressionModel{GLM.LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}

weight ~ 1 + sex + age + sex &amp; age

Coefficients:
──────────────────────────────────────────────────────────────────────────────
                     Coef.  Std. Error       t  Pr(&gt;|t|)  Lower 95%  Upper 95%
──────────────────────────────────────────────────────────────────────────────
(Intercept)       51.6158     3.05051    16.92    &lt;1e-09   44.9693    58.2622
sex: male        -54.5505     4.31407   -12.64    &lt;1e-07  -63.95     -45.1509
age                3.69845    0.183122   20.20    &lt;1e-09    3.29946    4.09744
sex: male &amp; age    4.19947    0.258974   16.22    &lt;1e-08    3.63521    4.76372
──────────────────────────────────────────────────────────────────────────────</pre><p>Is this model just a poor fit to the data? We can plot the effects and see that&#39;s not the case. For example purposes, we&#39;ll create a reference grid that does not correspond to a fully balanced design and call <code>effects!</code> to insert the effects-related columns. In particular, we&#39;ll take odd ages for males and even ages for females.</p><pre><code class="language-julia">refgrid = copy(growthdata)
filter!(refgrid) do row
  return mod(row.age, 2) == (row.sex == &quot;male&quot;)
end
effects!(refgrid, @formula(weight ~ 1 + sex * age), mod_uncentered)</code></pre><table class="data-frame"><thead><tr><th></th><th>age</th><th>sex</th><th>weight</th><th>err</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>8 rows × 4 columns</p><tr><th>1</th><td>13</td><td>male</td><td>99.7383</td><td>0.766054</td></tr><tr><th>2</th><td>15</td><td>male</td><td>115.534</td><td>0.5015</td></tr><tr><th>3</th><td>17</td><td>male</td><td>131.33</td><td>0.429459</td></tr><tr><th>4</th><td>19</td><td>male</td><td>147.126</td><td>0.620997</td></tr><tr><th>5</th><td>14</td><td>female</td><td>103.394</td><td>0.620997</td></tr><tr><th>6</th><td>16</td><td>female</td><td>110.791</td><td>0.429459</td></tr><tr><th>7</th><td>18</td><td>female</td><td>118.188</td><td>0.5015</td></tr><tr><th>8</th><td>20</td><td>female</td><td>125.585</td><td>0.766054</td></tr></tbody></table><p>Note that the column corresponding to the response variable <code>weight</code> has been overwritten with the effects prediction and that only the standard error is provided: the <a href="api/#Effects.effects!-Tuple{DataFrames.DataFrame, StatsModels.FormulaTerm, StatsBase.RegressionModel}"><code>effects!</code></a> method does less work than the <a href="api/#Effects.effects-Tuple{Dict, StatsModels.FormulaTerm, StatsBase.RegressionModel}"><code>effects</code></a> convenience method.</p><p>We can add the confidence interval bounds in and plot our predictions:</p><pre><code class="language-">refgrid[!, :lower] = @. refgrid.weight - 1.96 * refgrid.err
refgrid[!, :upper] = @. refgrid.weight + 1.96 * refgrid.err
sort!(refgrid, [:age])

plt = data(refgrid) * mapping(:age, :weight; lower=:lower, upper=:upper, color=:sex) *
      (visual(Lines) + visual(LinesFill))
draw(plt)</code></pre><p>We can also add in the raw data to check the model fit:</p><pre><code class="language-">draw(plt + data(growthdata) * mapping(:age, :weight; color=:sex) * visual(Scatter))</code></pre><p>The model seems to be doing a good job. Indeed it is, and as pointed out in the <a href="https://beacon-biosignals.github.io/StandardizedPredictors.jl/dev/">StandardizedPredictors.jl</a> docs, the problem is that we should center the <code>age</code> variable. While we&#39;re at it, we&#39;ll also set the contrasts for <code>sex</code> to be effects coded.</p><pre><code class="language-">using StandardizedPredictors
contrasts = Dict(:age =&gt; Center(15), :sex =&gt; EffectsCoding())
mod_centered = lm(@formula(weight ~ 1 + sex * age), growthdata; contrasts=contrasts)</code></pre><p>All of the estimates have now changed because the parameterization is completely different, but the predictions and thus the effects remain unchanged:</p><pre><code class="language-">refgrid_centered = copy(growthdata)
effects!(refgrid_centered, @formula(weight ~ 1 + sex * age), mod_centered; contrasts=contrasts)
refgrid_centered[!, :lower] = @. refgrid_centered.weight - 1.96 * refgrid_centered.err
refgrid_centered[!, :upper] = @. refgrid_centered.weight + 1.96 * refgrid_centered.err
sort!(refgrid_centered, [:age])

plt = data(refgrid_centered) * mapping(:age, :weight; lower=:lower, upper=:upper, color=:sex) *
      (visual(Lines) + visual(LinesFill))
draw(plt)</code></pre><p>Understanding lower-level terms in the presence of interactions can be particularly tricky, and effect plots are also useful for this. For example, if we want to examine the effect of <code>sex</code> at a <em>typical</em>  <code>age</code>, then we would need some way to reduce <code>age</code> to <code>typical</code> values. By default, <code>effects[!]</code> will take use the mean of all model terms not specified in the effects formula as representative values. Looking at <code>sex</code>, we see that</p><pre><code class="language-julia">design = Dict(:sex =&gt; unique(growthdata.sex))
effects(design,  @formula(weight ~ 1 + sex), mod_uncentered)</code></pre><table class="data-frame"><thead><tr><th></th><th>sex</th><th>weight</th><th>err</th><th>lower</th><th>upper</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>2 rows × 5 columns</p><tr><th>1</th><td>male</td><td>92.7354</td><td>2.17734</td><td>90.558</td><td>94.9127</td></tr><tr><th>2</th><td>female</td><td>147.286</td><td>2.17734</td><td>145.108</td><td>149.463</td></tr></tbody></table><p>correspond to the model&#39;s estimate of weights for each sex at the average age in the dataset. (Note that this is not quite the same as the average weight of each sex across all ages.) Like all effects predictions, this is invariant to contrast coding:</p><pre><code class="language-">effects(design,  @formula(weight ~ 1 + sex), mod_centered; contrasts=contrasts)</code></pre></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.3 on <span class="colophon-date" title="Tuesday 29 June 2021 16:15">Tuesday 29 June 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
